{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306668e8-ad7d-4ef7-b61c-2d1f8d8a2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef26cb3-3fc2-4bc1-aea4-7a271c81454b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disaster</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18769</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[13, 22, 15], [13, 22, 15], [13, 22, 15], [1...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18627</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18367</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[2, 3, 2], [2, 3, 2], [3, 3, 3], [2, 3, 2], ...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14623</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20951</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[19, 22, 24], [18, 21, 24], [14, 17, 19], [1...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15603</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[2, 3, 3], [3, 4, 3], [8, 12, 11], [27, 37, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[67, 89, 96], [67, 89, 96], [67, 89, 96], [6...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17420</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>3</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15384 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       disaster                                              image label  \\\n",
       "18769       1.0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...     0   \n",
       "23335       0.0  [[[13, 22, 15], [13, 22, 15], [13, 22, 15], [1...     0   \n",
       "18627       1.0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...     0   \n",
       "18367       1.0  [[[2, 3, 2], [2, 3, 2], [3, 3, 3], [2, 3, 2], ...     0   \n",
       "14623       1.0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...     0   \n",
       "...         ...                                                ...   ...   \n",
       "20951       0.0  [[[19, 22, 24], [18, 21, 24], [14, 17, 19], [1...     0   \n",
       "15603       1.0  [[[2, 3, 3], [3, 4, 3], [8, 12, 11], [27, 37, ...     0   \n",
       "23468       0.0  [[[67, 89, 96], [67, 89, 96], [67, 89, 96], [6...     0   \n",
       "14357       1.0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...     3   \n",
       "17420       1.0  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...     3   \n",
       "\n",
       "       height  width   size  \n",
       "18769     124    124  15376  \n",
       "23335     124    124  15376  \n",
       "18627     124    124  15376  \n",
       "18367     124    124  15376  \n",
       "14623     124    124  15376  \n",
       "...       ...    ...    ...  \n",
       "20951     124    124  15376  \n",
       "15603     124    124  15376  \n",
       "23468     124    124  15376  \n",
       "14357     124    124  15376  \n",
       "17420     124    124  15376  \n",
       "\n",
       "[15384 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading from HDF5\n",
    "df = pd.read_hdf('../../data/CNN Disaster/data.h5', 'df')\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ec364-84c4-47b9-94a6-526be6cfeb60",
   "metadata": {},
   "source": [
    "### Split, Balance and normalizing the dataset\n",
    "\n",
    "This code splits the dataset into a 20/80 test train split. It also normalizes the RGB values from 0-1 and applies sampling to balance the two labels found in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54494bc6-4280-4094-a072-0dda6c285490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "After sampling data\n",
      "\n",
      "Counts for each disaster type:\n",
      " 1.0    7004\n",
      "0.0    7004\n",
      "Name: disaster, dtype: int64\n",
      "\n",
      "Proportions for each disaster type:\n",
      " 1.0    0.5\n",
      "0.0    0.5\n",
      "Name: disaster, dtype: float64\n",
      "\n",
      "Damage level distribution for Midwest flooding:\n",
      "0    0.960166\n",
      "1    0.017561\n",
      "2    0.013135\n",
      "3    0.009138\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Damage level distribution for SoCal fire:\n",
      "0    0.866077\n",
      "3    0.121216\n",
      "1    0.008709\n",
      "2    0.003998\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def balance_data(df, n_samples=None, random_state=42):\n",
    "    new_df = pd.DataFrame()\n",
    "    for label in df['disaster'].unique():\n",
    "        label_df = df[df['disaster'] == label]\n",
    "        if n_samples is None:\n",
    "            n_samples = len(label_df)\n",
    "        resampled_df = resample(label_df, replace=True, n_samples=n_samples, random_state=random_state)\n",
    "        new_df = pd.concat([new_df, resampled_df], axis=0)\n",
    "    return new_df\n",
    "\n",
    "min_samples = min(df['disaster'].value_counts())\n",
    "\n",
    "balanced__df = balance_data(df, n_samples=min_samples)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"After sampling data\")\n",
    "\n",
    "disaster_counts = balanced__df['disaster'].value_counts()\n",
    "print(\"\\nCounts for each disaster type:\\n\", disaster_counts)\n",
    "\n",
    "total_records = disaster_counts.sum()\n",
    "proportions = disaster_counts / total_records\n",
    "print(\"\\nProportions for each disaster type:\\n\", proportions)\n",
    "\n",
    "print(\"\\nDamage level distribution for Midwest flooding:\")\n",
    "print(balanced__df[balanced__df['disaster'] == 0]['label'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDamage level distribution for SoCal fire:\")\n",
    "print(balanced__df[balanced__df['disaster'] == 1]['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43641f3c-97f0-40fd-8cb4-dc489478b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_images = []\n",
    "for image in balanced__df[\"image\"].values:\n",
    "    float_image = np.array(image).astype(np.float32)\n",
    "    float_images.append(float_image)\n",
    "\n",
    "float_images = np.array(float_images)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ab47e7-e179-4467-a650-adcbf96c71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(float_images, balanced__df[[\"disaster\", \"label\"]], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05392e49-08f9-40eb-a76a-d4be6ce37903",
   "metadata": {},
   "source": [
    "### Rotate The Images\n",
    "\n",
    "Rotating the images 180 degrees and then 90* degrees gives us the images rotated at 0, 90, 180, and 270 degrees giving us a lot more data to work with. \n",
    "\n",
    "\\* On bigger images the 90 degree rotation were disabled due to the large amounts of data created and limits on GPU memory size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0c7890-91bf-4c3c-aced-fb833c599980",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cnn = y_train_cnn[\"disaster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f0f51b-9e12-4bd4-9ae8-21f652340b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "\n",
    "def rotate_images(X_train, angle):\n",
    "    num_images = X_train.shape[0]\n",
    "    rotated_images = []\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image = X_train[i]\n",
    "        rotated_image = rotate(image, angle, preserve_range=True).astype(np.float32)  # Rotate image\n",
    "        rotated_images.append(rotated_image)\n",
    "\n",
    "    return np.array(rotated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ea5673-587b-4a83-ba15-e01ca94252eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rotated = rotate_images(X_train_cnn, angle=180)\n",
    "\n",
    "X_train_combined = np.concatenate([X_train_cnn, X_train_rotated], axis=0)\n",
    "\n",
    "num_rotated_images = X_train_rotated.shape[0]\n",
    "rotated_labels = y_train_cnn[:num_rotated_images] \n",
    "\n",
    "y_train_combined = np.concatenate([y_train_cnn, rotated_labels], axis=0)\n",
    "X_train_combined, y_train_combined = shuffle(X_train_combined, y_train_combined, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d82fde6-56be-442f-9fff-325a15721fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_train_rotated = rotate_images(X_train_combined, angle=90)\n",
    "\n",
    "X_train_combined = np.concatenate([X_train_combined, X_train_rotated], axis=0)\n",
    "\n",
    "num_rotated_images = X_train_rotated.shape[0]\n",
    "rotated_labels = y_train_combined[:num_rotated_images]\n",
    "\n",
    "y_train_combined = np.concatenate([y_train_combined, rotated_labels], axis=0)\n",
    "X_train_combined, y_train_combined = shuffle(X_train_combined, y_train_combined, random_state=42)   \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c0b73e-c64b-4903-a391-07574f068a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22412, 124, 124, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fc8034a-3850-4fe7-8f94-2302beb533f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22412, 2802, 11.112873800269691)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_combined), len(X_test_cnn), len(X_test_cnn)/(len(X_train_combined)+ len(X_test_cnn))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f472a1-31ae-4855-8ba2-9c3fa90dcf3b",
   "metadata": {},
   "source": [
    "### Rezising the images\n",
    "Optinally resize the images, this operating is ran on multiple threads to utelize full system resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8002e8a6-ea18-4dff-988b-5390122a4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "def resize_image(image):\n",
    "    # Resize Image to (224, 224)\n",
    "    return resize(image, (224, 224), anti_aliasing=True, preserve_range=True).astype(image.dtype)\n",
    "\n",
    "def process_images(image_list):\n",
    "    # Using threads, resize every image and return a list with all images\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        return list(executor.map(resize_image, image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242a2ae4-60b0-486f-b8a0-c4593de4c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = process_images(X_train_combined)\n",
    "X_test_cnn = process_images(X_test_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd22f9b0-f323-4ab1-8237-77a202b709d9",
   "metadata": {},
   "source": [
    "### Save Dataset\n",
    "\n",
    "Test/Train dataset is saved to NPZ. The damage labels are also saved used to analyze the results of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb23cde5-b1cb-4ad8-aeea-8aed1fae9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to NPZ\n",
    "np.savez('../../data/CNN Disaster/train_data.npz', images=X_train_combined, labels=y_train_combined)\n",
    "np.savez('../../data/CNN Disaster/test_data.npz', images=X_test_cnn, labels=y_test_cnn[\"disaster\"].values, damage_labels=y_test_cnn[\"label\"].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
